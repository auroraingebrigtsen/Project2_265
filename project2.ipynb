{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import box_convert, box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Object Localization\n",
    "#### First we load and inspect the localization_*** datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('data/localization_train.pt')\n",
    "val_data = torch.load('data/localization_val.pt')\n",
    "test_data = torch.load('data/localization_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Val data size: {len(val_data)}')\n",
    "print(f'Test data size: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img, first_label = train_data[0]\n",
    "\n",
    "print(f'Shape of first image: {first_img.shape}')\n",
    "print(f'Type of first image: {type(first_img)}')\n",
    "\n",
    "print(f'\\nShape of first label: {first_label.shape}')\n",
    "print(f'Type of first label: {type(first_label)})')\n",
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in train_data:\n",
    "    if label[0] == 0:\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_instances(data, data_name=None) -> None:\n",
    "    \"\"\"Counts the number of instances of each class in a dataset\"\"\"\n",
    "    counter = Counter([int(label[-1]) for _, label in data])\n",
    "    sorted_counter = dict(sorted(counter.items()))\n",
    "    if data_name is not None:\n",
    "        print(f'Class distribution in {data_name}')\n",
    "    for key, value in sorted_counter.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "count_instances(train_data, 'Training Data')\n",
    "count_instances(val_data, 'Validation Data')\n",
    "count_instances(test_data, 'Test Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting one image from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(8,3))\n",
    "\n",
    "for i, ax in enumerate(axes.flat): \n",
    "    img, bbox = next((img, label[1:5]) for img, label in train_data if int(label[-1]) == i)\n",
    "    img_height, img_width = train_data[0][0].shape[-2], train_data[0][0].shape[-1]\n",
    "\n",
    "    img = (img * 255).byte()\n",
    "\n",
    "    bbox[0] *= img_width\n",
    "    bbox[1] *= img_height\n",
    "    bbox[2] *= img_width\n",
    "    bbox[3] *= img_height\n",
    "\n",
    "    bbox = bbox.type(torch.uint8)\n",
    "\n",
    "    converted_bbox = box_convert(bbox, in_fmt='cxcywh', out_fmt='xyxy')\n",
    "\n",
    "    img_with_bbox = draw_bounding_boxes(img, converted_bbox.unsqueeze(0), colors='red')\n",
    "    img_with_bbox  = img_with_bbox.numpy().transpose((1, 2, 0))\n",
    "    ax.imshow(img_with_bbox, cmap='gray')\n",
    "    ax.set_title(i)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(data:torch.tensor, class_label:int, start_idx:int=0) -> None:\n",
    "    \"\"\"Plots a subplot with 10 images from a given class, starting at a chosen index\"\"\"\n",
    "    class_images = [img for img, label in data if int(label[-1]) == class_label]\n",
    "    bboxes = [label[1:5] for img, label in data if int(label[-1]) == class_label]\n",
    "    _, axes = plt.subplots(nrows=2, ncols=5, figsize=(8,3))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        idx = start_idx + i\n",
    "        img = class_images[idx]\n",
    "        bbox = bboxes[idx]\n",
    "\n",
    "        img_height, img_width = train_data[0][0].shape[-2], train_data[0][0].shape[-1]\n",
    "\n",
    "        img = (img * 255).byte()\n",
    "\n",
    "        bbox[0] *= img_width\n",
    "        bbox[1] *= img_height\n",
    "        bbox[2] *= img_width\n",
    "        bbox[3] *= img_height\n",
    "\n",
    "        bbox = bbox.type(torch.uint8)\n",
    "\n",
    "        converted_bbox = box_convert(bbox, in_fmt='cxcywh', out_fmt='xyxy')\n",
    "\n",
    "        img_with_bbox = draw_bounding_boxes(img, converted_bbox.unsqueeze(0), colors='red')\n",
    "        img_with_bbox  = img_with_bbox.numpy().transpose((1, 2, 0))\n",
    "        ax.imshow(img_with_bbox, cmap='gray')\n",
    "        plt.suptitle(f'CLASS {class_label} - Image {start_idx} to {idx}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_class(train_data, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a normalizer and a preprocessor TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img for img, _ in train_data])\n",
    "\n",
    "# Define normalizer\n",
    "normalizer_pipe = transforms.Normalize(\n",
    "    imgs.mean(dim=(0, 2, 3)), \n",
    "    imgs.std(dim=(0, 2, 3))\n",
    "    )\n",
    "\n",
    "# Define preprocessor including the normalizer\n",
    "preprocessor = transforms.Compose([\n",
    "            normalizer_pipe\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('data/localization_train.pt')\n",
    "val_data = torch.load('data/localization_val.pt')\n",
    "test_data = torch.load('data/localization_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(preprocessor(img), label) for img, label in train_data]\n",
    "val_data = [(preprocessor(img), label) for img, label in val_data]\n",
    "test_data = [(preprocessor(img), label) for img, label in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFn(nn.Module):\n",
    "    \"\"\"Custom loss function\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.L_a = nn.BCEWithLogitsLoss()  # detection loss\n",
    "        self.L_b = nn.MSELoss()  # localization loss\n",
    "        self.L_c = nn.CrossEntropyLoss()  # classification loss\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        det_pred = y_pred[:, 0]\n",
    "        bbox_pred = y_pred[:, 1:5]\n",
    "        class_pred = y_pred[:, 5:]\n",
    "\n",
    "        det_true = y_true[:, 0]\n",
    "        bbox_true = y_true[:, 1:5]\n",
    "        class_true = y_true[:, -1].long()\n",
    "\n",
    "        L_a = self.L_a(det_pred, det_true)\n",
    "\n",
    "        object_detected = det_true == 1\n",
    "\n",
    "        L_b = self.L_b(bbox_pred[object_detected], bbox_true[object_detected])\n",
    "        L_c = self.L_c(class_pred[object_detected], class_true[object_detected])\n",
    "\n",
    "        return L_a + L_b + L_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute size of fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_size(input_size, layer):\n",
    "    H_in = input_size[0]\n",
    "    W_in = input_size[1]\n",
    "    C_in = layer.in_channels\n",
    "    C_out = layer.out_channels\n",
    "    kernel_size = layer.kernel_size\n",
    "    padding = layer.padding\n",
    "    stride = layer.stride\n",
    "\n",
    "    H_out = (H_in+2*padding[0]-kernel_size[0])/stride[0]\n",
    "    W_out = (W_in+2*padding[1]-kernel_size[1])/stride[1]\n",
    "\n",
    "    return H_out * W_out * C_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, device=device, dtype=torch.double)\n",
    "conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, device=device, dtype=torch.double)\n",
    "conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_pipe(layers, input_size, num_outputs):\n",
    "    output_size = input_size\n",
    "    for layer in layers:\n",
    "        output_size = get_output_size(output_size, layer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, device=device, dtype=torch.double)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, device=device, dtype=torch.double)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, device=device, dtype=torch.double)\n",
    "        self.fc1 = nn.Linear(12*15*64, 15, device=device, dtype=torch.double)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance(model, loader):\n",
    "    '''\n",
    "    Function that uses a model to predict and calculate accuracy\n",
    "    '''\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iou_sum = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device, dtype=torch.double)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            det_pred = F.sigmoid(outputs[:, 0])\n",
    "            object_detected = det_pred > 0.5\n",
    "\n",
    "            label_pred = outputs[:, 5:]\n",
    "            _, class_pred = torch.max(label_pred, dim=1)\n",
    "\n",
    "            det_true = labels[:, 0].int()\n",
    "            class_true = labels[:, -1].int()\n",
    "\n",
    "            total += labels.shape[0]\n",
    "            correct += ((object_detected == 0) & (det_true == 0)).sum()\n",
    "            correct += ((object_detected == 1) & (det_true == 1) & (class_pred == class_true)).sum()\n",
    "\n",
    "            bbox_pred = outputs[:, 1:5]\n",
    "            bbox_true = labels[:, 1:5]\n",
    "\n",
    "            iou_sum += box_iou(bbox_pred[object_detected], bbox_true[object_detected]).sum()\n",
    "            print(iou_sum)\n",
    "\n",
    "    acc =  correct / total\n",
    "    iou = iou_sum / total\n",
    "\n",
    "    performance = (acc + iou) / 2\n",
    "    \n",
    "    return acc, iou, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss:list, val_loss:list, title:str) -> None:\n",
    "    \"\"\"Plots the training and validation loss\"\"\"\n",
    "    _, ax = plt.subplots()\n",
    "    ax.plot(np.arange(1,len(train_loss)+1), train_loss, label='Training loss')\n",
    "    ax.plot(np.arange(1,len(val_loss)+1), val_loss, label='Validation loss')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "    \n",
    "    n_batch_train = len(train_loader)\n",
    "    n_batch_val = len(val_loader)\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device, dtype=torch.double)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        model.eval()\n",
    "\n",
    "        with torch.inference_mode(): # <-- Equivalent to no_grad, if no error is provided this is preferred.\n",
    "            for imgs, labels in val_loader:\n",
    "\n",
    "                imgs = imgs.to(device=device, dtype=torch.double)\n",
    "                labels = labels.to(device=device, dtype=torch.double)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "            \n",
    "        losses_train.append(loss_train / n_batch_train)\n",
    "        losses_val.append(loss_val / n_batch_val)\n",
    "\n",
    "        #if epoch == 1 or epoch % 10 == 0:\n",
    "        print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(datetime.now().strftime('%H:%M:%S'), epoch, loss_train / n_batch_train))\n",
    "        print('{}  |  Epoch {}  |  Validation loss {:.3f}'.format(datetime.now().strftime('%H:%M:%S'), epoch, loss_val / n_batch_val))\n",
    "\n",
    "    train_acc, train_iou, train_performance = compute_performance(model, train_loader)\n",
    "    val_acc, val_iou, val_performance = compute_performance(model, val_loader)\n",
    "    print(f'Training performance: Accuracy = {train_acc}, IOU = {train_iou}, Overall = {train_performance}')\n",
    "    print(f'Training performance: Accuracy = {val_acc}, IOU = {val_iou}, Overall = {val_performance}')\n",
    "\n",
    "    return losses_train, losses_val, train_performance, val_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=512, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=512, shuffle=False)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model = MyCNN()\n",
    "model.to(device=device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0, weight_decay=0)\n",
    "loss_fn = LossFn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, loss_val, train_perform, val_perform = train(\n",
    "    n_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ")\n",
    "\n",
    "plot_loss(loss_train, loss_val, 'Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, iou, performance = compute_performance(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
