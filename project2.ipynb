{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import box_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_default_dtype(torch.double)\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Object Localization\n",
    "#### First we load and inspect the localization_*** datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('data/localization_train.pt')\n",
    "val_data = torch.load('data/localization_val.pt')\n",
    "test_data = torch.load('data/localization_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Val data size: {len(val_data)}')\n",
    "print(f'Test data size: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img, first_label = train_data[0]\n",
    "\n",
    "print(f'Shape of first image: {first_img.shape}')\n",
    "print(f'Type of first image: {type(first_img)}')\n",
    "\n",
    "print(f'\\nShape of first label: {first_label.shape}')\n",
    "print(f'Type of first label: {type(first_label)})')\n",
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_instances(data, data_name=None) -> None:\n",
    "    \"\"\"Counts the number of instances of each class in a dataset\"\"\"\n",
    "    counter = Counter([int(label[-1]) for _, label in data])\n",
    "    sorted_counter = dict(sorted(counter.items()))\n",
    "    if data_name is not None:\n",
    "        print(f'Class distribution in {data_name}')\n",
    "    for key, value in sorted_counter.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "count_instances(train_data, 'Training Data')\n",
    "count_instances(val_data, 'Validation Data')\n",
    "count_instances(test_data, 'Test Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0].shape\n",
    "#hÃ¸yde bredde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting one image from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(8,3))\n",
    "\n",
    "for i, ax in enumerate(axes.flat): \n",
    "    img, bbox = next((img, label[1:5]) for img, label in train_data if int(label[-1]) == i)\n",
    "    img_height, img_width = train_data[0][0].shape[-2], train_data[0][0].shape[-1]\n",
    "\n",
    "    img = (img * 255).byte()\n",
    "    bbox = (bbox * 255).byte()\n",
    "\n",
    "    converted_bbox = box_convert(bbox, in_fmt='cxcywh', out_fmt='xyxy')\n",
    "\n",
    "    img_with_bbox = draw_bounding_boxes(img, converted_bbox.unsqueeze(0), colors='red')\n",
    "    img_with_bbox  = img_with_bbox.numpy().transpose((1, 2, 0))\n",
    "    ax.imshow(img_with_bbox, cmap='gray')\n",
    "    ax.set_title(i)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(data:torch.tensor, class_label:int, start_idx:int=0) -> None:\n",
    "    \"\"\"Plots a subplot with 10 images from a given class, starting at a chosen index\n",
    "    Parameters:\n",
    "    data: torch.tensor\n",
    "        Data containing images and labels\n",
    "    class_label: int\n",
    "        The class to plot images from\n",
    "    start_idx: int\n",
    "        The index of the first image to be plotted. If start_idx=n, the subplot will contain \n",
    "        the n'th to the n+10'th image from the class\n",
    "    Returns:\n",
    "    None\"\"\"\n",
    "    class_images = [img for img, label in data if int(label[-1]) == class_label]\n",
    "    _, axes = plt.subplots(nrows=2, ncols=5, figsize=(8,3))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        idx = start_idx + i\n",
    "        img = class_images[idx]\n",
    "        img = img.numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        plt.suptitle(f'CLASS {class_label} - Image {start_idx} to {idx}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_class(train_data, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a normalizer and a preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img for img, _ in train_data])\n",
    "\n",
    "# Define normalizer\n",
    "normalizer_pipe = transforms.Normalize(\n",
    "    imgs.mean(dim=(0, 2, 3)), \n",
    "    imgs.std(dim=(0, 2, 3))\n",
    "    )\n",
    "\n",
    "# Definer preprocessor including the normalizer\n",
    "preprocessor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalizer_pipe\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('data/localization_train.pt')\n",
    "val_data = torch.load('data/localization_val.pt')\n",
    "test_data = torch.load('data/localization_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
